# FFmpeg C API ì‹¬í™”

**ëª©í‘œ**: FFmpeg C APIë¡œ ê³ ì„±ëŠ¥ ì¸ë„¤ì¼ ì¶”ì¶œ (p99 < 50ms)  
**ë‚œì´ë„**: â­â­â­â­â­ (ìµœê³ ê¸‰)  
**ì˜ˆìƒ ì‹œê°„**: 10-12ì‹œê°„ (ì •ë… + ì‹¤ìŠµ)  
**ì„ í–‰ ê³¼ì •**: [94-napi-native-addon.md](94-napi-native-addon.md)

---

## ğŸ“‹ ëª©ì°¨

1. [FFmpeg C API ê¸°ì´ˆ](#part-1-ffmpeg-c-api-ê¸°ì´ˆ)
2. [ë¹„ë””ì˜¤ ë””ì½”ë”©](#part-2-ë¹„ë””ì˜¤-ë””ì½”ë”©)
3. [ì¸ë„¤ì¼ ì¶”ì¶œ](#part-3-ì¸ë„¤ì¼-ì¶”ì¶œ)
4. [ë©”ëª¨ë¦¬ ê´€ë¦¬ (RAII)](#part-4-ë©”ëª¨ë¦¬-ê´€ë¦¬-raii)

---

## Part 1: FFmpeg C API ê¸°ì´ˆ

### 1.1 FFmpeg ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¡°

```
FFmpeg C API:

libavformat: ì»¨í…Œì´ë„ˆ í¬ë§· (MP4, MOV, AVI)
  â””â”€ AVFormatContext: íŒŒì¼ ì •ë³´
  â””â”€ AVStream: ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼

libavcodec: ì½”ë± (H.264, H.265, AAC)
  â””â”€ AVCodecContext: ë””ì½”ë”/ì¸ì½”ë” ì„¤ì •
  â””â”€ AVPacket: ì••ì¶•ëœ ë°ì´í„°
  â””â”€ AVFrame: ì••ì¶• í•´ì œëœ ë°ì´í„° (í”½ì…€)

libavutil: ìœ í‹¸ë¦¬í‹°
  â””â”€ AVDictionary: ì˜µì…˜
  â””â”€ av_malloc/av_free: ë©”ëª¨ë¦¬ ê´€ë¦¬

libswscale: ì´ë¯¸ì§€ ë³€í™˜ (RGB â†” YUV, ë¦¬ì‚¬ì´ì¦ˆ)
  â””â”€ SwsContext: ë³€í™˜ ì»¨í…ìŠ¤íŠ¸
```

---

### 1.2 í—¤ë” íŒŒì¼

```cpp
// native/src/ffmpeg_utils.h
#ifndef FFMPEG_UTILS_H
#define FFMPEG_UTILS_H

extern "C" {
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libavutil/imgutils.h>
#include <libswscale/swscale.h>
}

#include <memory>
#include <string>
#include <stdexcept>

// RAII ë˜í¼ (ë‹¤ìŒ ì„¹ì…˜)
class VideoDecoder;
class FrameConverter;

#endif  // FFMPEG_UTILS_H
```

---

### 1.3 FFmpeg ì„¤ì¹˜

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install libavformat-dev libavcodec-dev libavutil-dev libswscale-dev

# í™•ì¸
pkg-config --modversion libavformat
# 6.0
```

---

### 1.4 binding.gyp ìˆ˜ì •

```python
# native/binding.gyp
{
  "targets": [
    {
      "target_name": "native",
      "sources": [
        "src/module.cpp",
        "src/thumbnail.cpp",
        "src/ffmpeg_utils.cpp"
      ],
      "include_dirs": [
        "<!@(node -p \"require('node-addon-api').include\")",
        "<!@(pkg-config --cflags-only-I libavformat libavcodec libavutil libswscale | sed 's/-I//g')"
      ],
      "libraries": [
        "<!@(pkg-config --libs libavformat libavcodec libavutil libswscale)"
      ],
      "defines": [
        "NAPI_DISABLE_CPP_EXCEPTIONS"
      ],
      "cflags!": ["-fno-exceptions"],
      "cflags_cc!": ["-fno-exceptions"],
      "cflags_cc": ["-std=c++17"],
      "xcode_settings": {
        "GCC_ENABLE_CPP_EXCEPTIONS": "YES",
        "CLANG_CXX_LIBRARY": "libc++",
        "MACOSX_DEPLOYMENT_TARGET": "10.15",
        "OTHER_CPLUSPLUSFLAGS": ["-std=c++17"]
      }
    }
  ]
}
```

---

## Part 2: ë¹„ë””ì˜¤ ë””ì½”ë”©

### 2.1 íŒŒì¼ ì—´ê¸°

```cpp
// native/src/ffmpeg_utils.cpp
#include "ffmpeg_utils.h"

class VideoDecoder {
 public:
  VideoDecoder(const std::string& filename) {
    // AVFormatContext í• ë‹¹
    formatCtx_ = avformat_alloc_context();
    if (!formatCtx_) {
      throw std::runtime_error("Failed to allocate format context");
    }
    
    // íŒŒì¼ ì—´ê¸°
    if (avformat_open_input(&formatCtx_, filename.c_str(), nullptr, nullptr) < 0) {
      throw std::runtime_error("Failed to open input file");
    }
    
    // ìŠ¤íŠ¸ë¦¼ ì •ë³´ ì½ê¸°
    if (avformat_find_stream_info(formatCtx_, nullptr) < 0) {
      throw std::runtime_error("Failed to find stream info");
    }
    
    // ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
    videoStreamIdx_ = -1;
    for (unsigned int i = 0; i < formatCtx_->nb_streams; i++) {
      if (formatCtx_->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
        videoStreamIdx_ = i;
        break;
      }
    }
    
    if (videoStreamIdx_ == -1) {
      throw std::runtime_error("No video stream found");
    }
    
    // ì½”ë± íŒŒë¼ë¯¸í„°
    AVCodecParameters* codecpar = formatCtx_->streams[videoStreamIdx_]->codecpar;
    
    // ë””ì½”ë” ì°¾ê¸°
    const AVCodec* codec = avcodec_find_decoder(codecpar->codec_id);
    if (!codec) {
      throw std::runtime_error("Unsupported codec");
    }
    
    // ì½”ë± ì»¨í…ìŠ¤íŠ¸ í• ë‹¹
    codecCtx_ = avcodec_alloc_context3(codec);
    if (!codecCtx_) {
      throw std::runtime_error("Failed to allocate codec context");
    }
    
    // íŒŒë¼ë¯¸í„° ë³µì‚¬
    if (avcodec_parameters_to_context(codecCtx_, codecpar) < 0) {
      throw std::runtime_error("Failed to copy codec parameters");
    }
    
    // ë””ì½”ë” ì—´ê¸°
    if (avcodec_open2(codecCtx_, codec, nullptr) < 0) {
      throw std::runtime_error("Failed to open codec");
    }
  }
  
  ~VideoDecoder() {
    if (codecCtx_) {
      avcodec_free_context(&codecCtx_);
    }
    if (formatCtx_) {
      avformat_close_input(&formatCtx_);
    }
  }
  
  AVFormatContext* formatCtx() const { return formatCtx_; }
  AVCodecContext* codecCtx() const { return codecCtx_; }
  int videoStreamIdx() const { return videoStreamIdx_; }
  
 private:
  AVFormatContext* formatCtx_ = nullptr;
  AVCodecContext* codecCtx_ = nullptr;
  int videoStreamIdx_ = -1;
};
```

---

### 2.2 íŠ¹ì • ì‹œê°„ìœ¼ë¡œ ì‹œí¬

```cpp
class VideoDecoder {
 public:
  // ... ê¸°ì¡´ ì½”ë“œ
  
  bool SeekToTime(double timestamp) {
    // íƒ€ì„ë² ì´ìŠ¤ (ì‹œê°„ ë‹¨ìœ„)
    AVRational timeBase = formatCtx_->streams[videoStreamIdx_]->time_base;
    
    // ì´ˆ â†’ íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
    int64_t seekTarget = static_cast<int64_t>(timestamp / av_q2d(timeBase));
    
    // ì‹œí¬ (BACKWARD: ì´ì „ í‚¤í”„ë ˆì„)
    if (av_seek_frame(formatCtx_, videoStreamIdx_, seekTarget, AVSEEK_FLAG_BACKWARD) < 0) {
      return false;
    }
    
    // ë””ì½”ë” í”ŒëŸ¬ì‹œ
    avcodec_flush_buffers(codecCtx_);
    
    return true;
  }
};
```

---

### 2.3 í”„ë ˆì„ ë””ì½”ë”©

```cpp
class VideoDecoder {
 public:
  // ... ê¸°ì¡´ ì½”ë“œ
  
  AVFrame* DecodeFrameAt(double timestamp) {
    // ì‹œí¬
    if (!SeekToTime(timestamp)) {
      return nullptr;
    }
    
    AVPacket* packet = av_packet_alloc();
    AVFrame* frame = av_frame_alloc();
    
    if (!packet || !frame) {
      if (packet) av_packet_free(&packet);
      if (frame) av_frame_free(&frame);
      return nullptr;
    }
    
    // íƒ€ì„ë² ì´ìŠ¤
    AVRational timeBase = formatCtx_->streams[videoStreamIdx_]->time_base;
    
    // íŒ¨í‚· ì½ê¸°
    while (av_read_frame(formatCtx_, packet) >= 0) {
      if (packet->stream_index == videoStreamIdx_) {
        // ë””ì½”ë”ì— ì „ì†¡
        if (avcodec_send_packet(codecCtx_, packet) == 0) {
          // í”„ë ˆì„ ìˆ˜ì‹ 
          if (avcodec_receive_frame(codecCtx_, frame) == 0) {
            // íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸
            double frameTime = frame->pts * av_q2d(timeBase);
            
            if (frameTime >= timestamp) {
              av_packet_free(&packet);
              return frame;  // ì„±ê³µ
            }
          }
        }
      }
      
      av_packet_unref(packet);
    }
    
    // ì‹¤íŒ¨
    av_packet_free(&packet);
    av_frame_free(&frame);
    return nullptr;
  }
};
```

---

## Part 3: ì¸ë„¤ì¼ ì¶”ì¶œ

### 3.1 RGB ë³€í™˜

```cpp
class FrameConverter {
 public:
  FrameConverter(int srcWidth, int srcHeight, AVPixelFormat srcFormat,
                 int dstWidth, int dstHeight, AVPixelFormat dstFormat) {
    swsCtx_ = sws_getContext(
      srcWidth, srcHeight, srcFormat,
      dstWidth, dstHeight, dstFormat,
      SWS_BILINEAR,  // ë³´ê°„ ì•Œê³ ë¦¬ì¦˜
      nullptr, nullptr, nullptr
    );
    
    if (!swsCtx_) {
      throw std::runtime_error("Failed to create SwsContext");
    }
  }
  
  ~FrameConverter() {
    if (swsCtx_) {
      sws_freeContext(swsCtx_);
    }
  }
  
  AVFrame* Convert(AVFrame* srcFrame) {
    AVFrame* dstFrame = av_frame_alloc();
    if (!dstFrame) {
      return nullptr;
    }
    
    dstFrame->format = AV_PIX_FMT_RGB24;
    dstFrame->width = dstWidth_;
    dstFrame->height = dstHeight_;
    
    // ë²„í¼ í• ë‹¹
    if (av_frame_get_buffer(dstFrame, 0) < 0) {
      av_frame_free(&dstFrame);
      return nullptr;
    }
    
    // ë³€í™˜
    sws_scale(
      swsCtx_,
      srcFrame->data, srcFrame->linesize,
      0, srcFrame->height,
      dstFrame->data, dstFrame->linesize
    );
    
    return dstFrame;
  }
  
 private:
  SwsContext* swsCtx_ = nullptr;
  int dstWidth_;
  int dstHeight_;
};
```

---

### 3.2 JPEG ì¸ì½”ë”©

```cpp
#include <jpeglib.h>
#include <vector>

std::vector<uint8_t> EncodeJPEG(AVFrame* frame, int quality = 85) {
  // libjpeg ì´ˆê¸°í™”
  jpeg_compress_struct cinfo;
  jpeg_error_mgr jerr;
  
  cinfo.err = jpeg_std_error(&jerr);
  jpeg_create_compress(&cinfo);
  
  // ë©”ëª¨ë¦¬ ì¶œë ¥ ì„¤ì •
  unsigned char* outbuffer = nullptr;
  unsigned long outsize = 0;
  jpeg_mem_dest(&cinfo, &outbuffer, &outsize);
  
  // ì´ë¯¸ì§€ ì„¤ì •
  cinfo.image_width = frame->width;
  cinfo.image_height = frame->height;
  cinfo.input_components = 3;  // RGB
  cinfo.in_color_space = JCS_RGB;
  
  jpeg_set_defaults(&cinfo);
  jpeg_set_quality(&cinfo, quality, TRUE);
  
  // ì••ì¶• ì‹œì‘
  jpeg_start_compress(&cinfo, TRUE);
  
  // ë¼ì¸ë³„ ì¸ì½”ë”©
  while (cinfo.next_scanline < cinfo.image_height) {
    JSAMPROW row = frame->data[0] + cinfo.next_scanline * frame->linesize[0];
    jpeg_write_scanlines(&cinfo, &row, 1);
  }
  
  jpeg_finish_compress(&cinfo);
  
  // ê²°ê³¼ ë³µì‚¬
  std::vector<uint8_t> result(outbuffer, outbuffer + outsize);
  
  // ì •ë¦¬
  free(outbuffer);
  jpeg_destroy_compress(&cinfo);
  
  return result;
}
```

---

### 3.3 í†µí•©

```cpp
// native/src/thumbnail.cpp (ìˆ˜ì •)
#include "thumbnail.h"
#include "ffmpeg_utils.h"

void ThumbnailWorker::Execute() {
  try {
    // 1. ë¹„ë””ì˜¤ ì—´ê¸°
    VideoDecoder decoder(inputPath_);
    
    // 2. í”„ë ˆì„ ë””ì½”ë”©
    AVFrame* frame = decoder.DecodeFrameAt(timestamp_);
    if (!frame) {
      SetError("Failed to decode frame");
      return;
    }
    
    // 3. RGB ë³€í™˜
    FrameConverter converter(
      frame->width, frame->height, (AVPixelFormat)frame->format,
      320, 240, AV_PIX_FMT_RGB24
    );
    
    AVFrame* rgbFrame = converter.Convert(frame);
    av_frame_free(&frame);
    
    if (!rgbFrame) {
      SetError("Failed to convert frame");
      return;
    }
    
    // 4. JPEG ì¸ì½”ë”©
    jpegData_ = EncodeJPEG(rgbFrame, 85);
    av_frame_free(&rgbFrame);
    
  } catch (const std::exception& e) {
    SetError(e.what());
  }
}
```

---

## Part 4: ë©”ëª¨ë¦¬ ê´€ë¦¬ (RAII)

### 4.1 RAIIë€?

```
RAII = Resource Acquisition Is Initialization

ì›ì¹™:
âœ… ìƒì„±ìì—ì„œ ë¦¬ì†ŒìŠ¤ í• ë‹¹
âœ… ì†Œë©¸ìì—ì„œ ë¦¬ì†ŒìŠ¤ í•´ì œ
âœ… ì˜ˆì™¸ ì•ˆì „ì„±

ì¥ì :
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
- ì½”ë“œ ê°„ê²°í™”
- ìë™ ì •ë¦¬
```

---

### 4.2 unique_ptr with Custom Deleter

```cpp
// native/src/ffmpeg_utils.h
#include <memory>

// AVFrame Deleter
struct AVFrameDeleter {
  void operator()(AVFrame* frame) {
    if (frame) {
      av_frame_free(&frame);
    }
  }
};

// AVPacket Deleter
struct AVPacketDeleter {
  void operator()(AVPacket* packet) {
    if (packet) {
      av_packet_free(&packet);
    }
  }
};

// Alias
using AVFramePtr = std::unique_ptr<AVFrame, AVFrameDeleter>;
using AVPacketPtr = std::unique_ptr<AVPacket, AVPacketDeleter>;

// í—¬í¼ í•¨ìˆ˜
inline AVFramePtr MakeAVFrame() {
  return AVFramePtr(av_frame_alloc());
}

inline AVPacketPtr MakeAVPacket() {
  return AVPacketPtr(av_packet_alloc());
}
```

**ì‚¬ìš©**:
```cpp
AVFramePtr frame = MakeAVFrame();  // ìë™ í•´ì œ
if (!frame) {
  throw std::runtime_error("Failed to allocate frame");
}

// frame ì‚¬ìš©
// ...

// ì†Œë©¸ìì—ì„œ ìë™ìœ¼ë¡œ av_frame_free() í˜¸ì¶œ
```

---

### 4.3 VideoDecoder RAII ë¦¬íŒ©í† ë§

```cpp
class VideoDecoder {
 public:
  VideoDecoder(const std::string& filename) {
    // ... ì´ˆê¸°í™” (ì˜ˆì™¸ ë°œìƒ ì‹œ ì†Œë©¸ì í˜¸ì¶œ)
  }
  
  ~VideoDecoder() {
    // RAII: ì†Œë©¸ìì—ì„œ ìë™ ì •ë¦¬
    if (codecCtx_) {
      avcodec_free_context(&codecCtx_);
    }
    if (formatCtx_) {
      avformat_close_input(&formatCtx_);
    }
  }
  
  // ë³µì‚¬ ê¸ˆì§€ (ë¦¬ì†ŒìŠ¤ ì¤‘ë³µ í•´ì œ ë°©ì§€)
  VideoDecoder(const VideoDecoder&) = delete;
  VideoDecoder& operator=(const VideoDecoder&) = delete;
  
  // ì´ë™ í—ˆìš©
  VideoDecoder(VideoDecoder&& other) noexcept
    : formatCtx_(other.formatCtx_),
      codecCtx_(other.codecCtx_),
      videoStreamIdx_(other.videoStreamIdx_) {
    other.formatCtx_ = nullptr;
    other.codecCtx_ = nullptr;
  }
  
  AVFramePtr DecodeFrameAt(double timestamp) {
    if (!SeekToTime(timestamp)) {
      return nullptr;
    }
    
    auto packet = MakeAVPacket();
    auto frame = MakeAVFrame();
    
    if (!packet || !frame) {
      return nullptr;
    }
    
    AVRational timeBase = formatCtx_->streams[videoStreamIdx_]->time_base;
    
    while (av_read_frame(formatCtx_, packet.get()) >= 0) {
      if (packet->stream_index == videoStreamIdx_) {
        if (avcodec_send_packet(codecCtx_, packet.get()) == 0) {
          if (avcodec_receive_frame(codecCtx_, frame.get()) == 0) {
            double frameTime = frame->pts * av_q2d(timeBase);
            
            if (frameTime >= timestamp) {
              return frame;  // unique_ptr ì´ë™
            }
          }
        }
      }
      
      av_packet_unref(packet.get());
    }
    
    return nullptr;
  }
  
 private:
  AVFormatContext* formatCtx_ = nullptr;
  AVCodecContext* codecCtx_ = nullptr;
  int videoStreamIdx_ = -1;
};
```

---

### 4.4 ë©”ëª¨ë¦¬ í’€ (ì„ íƒ)

```cpp
// Arena60 MVP 2.0 íŒ¨í„´ ì ìš©
#include <queue>
#include <mutex>

class FramePool {
 public:
  explicit FramePool(size_t capacity) : capacity_(capacity) {}
  
  AVFramePtr Acquire() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!pool_.empty()) {
      AVFrame* frame = pool_.front();
      pool_.pop();
      return AVFramePtr(frame);
    }
    
    // í’€ì´ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆë¡œ í• ë‹¹
    return MakeAVFrame();
  }
  
  void Release(AVFrame* frame) {
    if (!frame) return;
    
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (pool_.size() < capacity_) {
      av_frame_unref(frame);  // ë°ì´í„° ì´ˆê¸°í™”
      pool_.push(frame);
    } else {
      av_frame_free(&frame);  // ìš©ëŸ‰ ì´ˆê³¼ ì‹œ í•´ì œ
    }
  }
  
  ~FramePool() {
    while (!pool_.empty()) {
      AVFrame* frame = pool_.front();
      pool_.pop();
      av_frame_free(&frame);
    }
  }
  
 private:
  size_t capacity_;
  std::queue<AVFrame*> pool_;
  std::mutex mutex_;
};

// ì „ì—­ í’€
static FramePool g_framePool(10);  // ìµœëŒ€ 10ê°œ ì¬ì‚¬ìš©
```

---

## ğŸ¯ ì‹¤ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### FFmpeg ì„¤ì •
- [ ] FFmpeg ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
- [ ] binding.gypì— FFmpeg ë§í¬
- [ ] í—¤ë” íŒŒì¼ include í™•ì¸

### ë¹„ë””ì˜¤ ë””ì½”ë”©
- [ ] AVFormatContext í• ë‹¹ ë° íŒŒì¼ ì—´ê¸°
- [ ] ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
- [ ] AVCodecContext ì´ˆê¸°í™”
- [ ] íŠ¹ì • ì‹œê°„ìœ¼ë¡œ ì‹œí¬ (av_seek_frame)
- [ ] í”„ë ˆì„ ë””ì½”ë”© (avcodec_send_packet/receive_frame)

### ì´ë¯¸ì§€ ë³€í™˜
- [ ] SwsContext ìƒì„± (sws_getContext)
- [ ] YUV â†’ RGB ë³€í™˜ (sws_scale)
- [ ] ë¦¬ì‚¬ì´ì¦ˆ (320x240)

### JPEG ì¸ì½”ë”©
- [ ] libjpeg ì´ˆê¸°í™”
- [ ] RGB â†’ JPEG ì••ì¶•
- [ ] í’ˆì§ˆ ì„¤ì • (85)

### ë©”ëª¨ë¦¬ ê´€ë¦¬
- [ ] RAII íŒ¨í„´ (ìƒì„±ì/ì†Œë©¸ì)
- [ ] unique_ptr with Custom Deleter
- [ ] ë³µì‚¬ ìƒì„±ì ì‚­ì œ (= delete)
- [ ] ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸ (valgrind)

---

## ğŸ“š ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸

### ê¸°ì´ˆ
1. **AVFormatContextë€?**
   - ì»¨í…Œì´ë„ˆ í¬ë§· ì •ë³´ (MP4, MOV ë“±)

2. **AVCodecContextë€?**
   - ì½”ë± (ë””ì½”ë”/ì¸ì½”ë”) ì„¤ì •

3. **AVFrame vs AVPacket?**
   - AVPacket: ì••ì¶•ëœ ë°ì´í„°
   - AVFrame: ì••ì¶• í•´ì œëœ ë°ì´í„° (í”½ì…€)

4. **av_seek_frameì˜ ì—­í• ì€?**
   - íŠ¹ì • ì‹œê°„ìœ¼ë¡œ ì´ë™

5. **SwsContextë€?**
   - ì´ë¯¸ì§€ ë³€í™˜ ì»¨í…ìŠ¤íŠ¸ (í¬ë§·, ë¦¬ì‚¬ì´ì¦ˆ)

### ì‹¬í™”
6. **RAIIì˜ ì¥ì ì€?**
   - ìë™ ë¦¬ì†ŒìŠ¤ í•´ì œ, ì˜ˆì™¸ ì•ˆì „ì„±

7. **unique_ptr Custom Deleter ì‚¬ìš© ì´ìœ ëŠ”?**
   - FFmpeg ë¦¬ì†ŒìŠ¤ (AVFrame ë“±)ëŠ” íŠ¹ìˆ˜ í•´ì œ í•¨ìˆ˜ í•„ìš”

8. **ë©”ëª¨ë¦¬ í’€ì˜ ì¥ì ì€?**
   - í• ë‹¹/í•´ì œ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
   - ì„±ëŠ¥ í–¥ìƒ

9. **avcodec_send_packet/receive_frame íŒ¨í„´ì€?**
   - ë””ì½”ë”ì— íŒ¨í‚· ì „ì†¡ â†’ í”„ë ˆì„ ìˆ˜ì‹ 
   - 1:N ê´€ê³„ (í•œ íŒ¨í‚·ì— ì—¬ëŸ¬ í”„ë ˆì„)

10. **YUV vs RGB ì°¨ì´ëŠ”?**
    - YUV: ë¹„ë””ì˜¤ ì••ì¶• í¬ë§· (íœ˜ë„ + ìƒ‰ì°¨)
    - RGB: ë””ìŠ¤í”Œë ˆì´ í¬ë§· (ë¹¨ê°• + ì´ˆë¡ + íŒŒë‘)

---

**ë‹¤ìŒ ë¬¸ì„œ**: [96-webgl-video-rendering.md](96-webgl-video-rendering.md) - WebGL ë¹„ë””ì˜¤ ë Œë”ë§
